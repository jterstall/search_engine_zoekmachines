{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/usr/local/lib/python3.4/dist-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#% cd telegraaf\n",
    "#!wget -r -np -k -A xml.gz http://data.politicalmashup.nl/arjan/telegraaf/\n",
    "#% cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "es = Elasticsearch([{'host': 'localhost', 'port': 9200}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/davidstap/anaconda3/Applications\n",
      "/home/davidstap/anaconda3/Applications/elasticsearch-1.7.1\n"
     ]
    }
   ],
   "source": [
    "% cd Applications\n",
    "% cd elasticsearch-1.7.1\n",
    "!./bin/elasticsearch -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Assignment  week 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook made by   (If not filled in correctly: 0 pts for assignment)\n",
    "\n",
    "__Name(s)__: \n",
    "\n",
    "__Student id(s)__ : \n",
    "\n",
    "### Pledge (taken from [Coursera's Honor Code](https://www.coursera.org/about/terms/honorcode) )\n",
    "\n",
    "\n",
    "\n",
    "Put here a selfie with your photo where you hold a signed paper with the following text: (if this is team work, put two selfies here). The link must be to some place on the web, not to a local file. **Assignments without the selfies will not be graded and receive 0 points.**\n",
    "\n",
    "> My answers to homework, quizzes and exams will be my own work (except for assignments that explicitly permit collaboration).\n",
    "\n",
    ">I will not make solutions to homework, quizzes or exams available to anyone else. This includes both solutions written by me, as well as any official solutions provided by the course staff.\n",
    "\n",
    ">I will not engage in any other activities that will dishonestly improve my results or dishonestly improve/hurt the results of others.\n",
    "\n",
    "<img src='link to your selfie'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/davidstap/anaconda3/telegraaf/data.politicalmashup.nl/arjan/telegraaf\n",
      "telegraaf-1918.xml.gz  telegraaf-1971.xml.gz  telegraaf-1983.xml.gz\r\n",
      "telegraaf-1922.xml.gz  telegraaf-1972.xml.gz  telegraaf-1984.xml.gz\r\n",
      "telegraaf-1923.xml.gz  telegraaf-1973.xml.gz  telegraaf-1985.xml.gz\r\n",
      "telegraaf-1951.xml.gz  telegraaf-1974.xml.gz  telegraaf-1986.xml.gz\r\n",
      "telegraaf-1961.xml.gz  telegraaf-1975.xml.gz  telegraaf-1987.xml.gz\r\n",
      "telegraaf-1962.xml.gz  telegraaf-1976.xml.gz  telegraaf-1988.xml.gz\r\n",
      "telegraaf-1963.xml.gz  telegraaf-1977.xml.gz  telegraaf-1989.xml.gz\r\n",
      "telegraaf-1965.xml.gz  telegraaf-1978.xml.gz  telegraaf-1990.xml.gz\r\n",
      "telegraaf-1966.xml.gz  telegraaf-1979.xml.gz  telegraaf-1991.xml.gz\r\n",
      "telegraaf-1968.xml.gz  telegraaf-1980.xml.gz  telegraaf-1992.xml.gz\r\n",
      "telegraaf-1969.xml.gz  telegraaf-1981.xml.gz  telegraaf-1993.xml.gz\r\n",
      "telegraaf-1970.xml.gz  telegraaf-1982.xml.gz  telegraaf-1994.xml.gz\r\n"
     ]
    }
   ],
   "source": [
    "%cd ../../telegraaf/data.politicalmashup.nl/arjan/telegraaf\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded: telegraaf-1993.xml.gz\n",
      "loaded: telegraaf-1979.xml.gz\n",
      "loaded: telegraaf-1973.xml.gz\n",
      "loaded: telegraaf-1951.xml.gz\n",
      "loaded: telegraaf-1987.xml.gz\n",
      "loaded: telegraaf-1980.xml.gz\n",
      "loaded: telegraaf-1983.xml.gz\n",
      "loaded: telegraaf-1970.xml.gz\n",
      "loaded: telegraaf-1988.xml.gz\n",
      "loaded: telegraaf-1992.xml.gz\n",
      "loaded: telegraaf-1978.xml.gz\n",
      "loaded: telegraaf-1981.xml.gz\n",
      "loaded: telegraaf-1984.xml.gz\n",
      "loaded: telegraaf-1994.xml.gz\n",
      "loaded: telegraaf-1918.xml.gz\n",
      "loaded: telegraaf-1971.xml.gz\n",
      "loaded: telegraaf-1974.xml.gz\n",
      "loaded: telegraaf-1961.xml.gz\n",
      "loaded: telegraaf-1977.xml.gz\n",
      "loaded: telegraaf-1982.xml.gz\n",
      "loaded: telegraaf-1966.xml.gz\n",
      "loaded: telegraaf-1968.xml.gz\n",
      "loaded: telegraaf-1922.xml.gz\n",
      "loaded: telegraaf-1963.xml.gz\n",
      "loaded: telegraaf-1985.xml.gz\n",
      "loaded: telegraaf-1975.xml.gz\n",
      "loaded: telegraaf-1972.xml.gz\n",
      "loaded: telegraaf-1962.xml.gz\n",
      "loaded: telegraaf-1986.xml.gz\n",
      "loaded: telegraaf-1989.xml.gz\n",
      "loaded: telegraaf-1969.xml.gz\n",
      "loaded: telegraaf-1990.xml.gz\n",
      "loaded: telegraaf-1923.xml.gz\n",
      "loaded: telegraaf-1991.xml.gz\n",
      "loaded: telegraaf-1965.xml.gz\n",
      "loaded: telegraaf-1976.xml.gz\n"
     ]
    }
   ],
   "source": [
    "import os  \n",
    "import gzip\n",
    "from xml.dom.minidom import parse, parseString\n",
    "\n",
    "# load all files and store in temporary xml_list\n",
    "xml_list = list()\n",
    "for fn in os.listdir('.'):\n",
    "     if os.path.isfile(fn):\n",
    "        infile = gzip.open('telegraaf-1951.xml.gz')\n",
    "        xml_list.append(infile.read())\n",
    "        \n",
    "        print ('loaded: '+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsed 0/35\n",
      "json_dumped 0/35"
     ]
    }
   ],
   "source": [
    "import xmltodict, json\n",
    "\n",
    "json_dump = list()\n",
    "\n",
    "for year in range(len(xml_list)):\n",
    "    o = xmltodict.parse(xml_list[year])\n",
    "    print('parsed '+str(year)+'/35')\n",
    "    # use xmltodict to convert xml file to json (elasticsearch needs json input)\n",
    "    #make json dump\n",
    "    json_dump.append(json.dumps(o)) # '{\"e\": {\"a\": [\"text\", \"text\"]}}'\n",
    "    print('json_dumped '+str(year)+'/35')\n",
    "    \n",
    "# PROBLEM: computer automatically restarts when almost finished (memory overload? size of files = 5.7GB)\n",
    "\n",
    "# maybe do half of all telegraaf years first, store to disk, then proceed with second half? \n",
    "# took about 30 minutes for almost all files before automatically restarting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "f = open('store.pckl', 'wb')\n",
    "pickle.dump(json_dump, f)\n",
    "f.close()\n",
    "\n",
    "f = open('store.pckl', 'rb')\n",
    "json_dump = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hallod\n"
     ]
    }
   ],
   "source": [
    "print(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'telegraaf-1951.xml.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-483-e7fee27a09d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# open and read gzipped xml file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0minfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgzip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'telegraaf-1951.xml.gz'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/davidstap/anaconda3/lib/python3.4/gzip.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(filename, mode, compresslevel, encoding, errors, newline)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mgz_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"t\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0mbinary_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"read\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"write\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mbinary_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/davidstap/anaconda3/lib/python3.4/gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[0mmode\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m             \u001b[0mfileobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'telegraaf-1951.xml.gz'"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "from xml.dom.minidom import parse, parseString\n",
    "\n",
    "# open and read gzipped xml file\n",
    "infile = gzip.open('telegraaf-1951.xml.gz')\n",
    "content = infile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<pm:KBroot xmlns:pm=\"http://www.politicalmashup.nl\" recordfile=\"\">\\n<pm:root><pm:docinfo/><pm:meta><dc:date xmlns:dc=\"http://purl.org/dc/elements/1.1/\">1951-07-02</dc:date><dc:subject xmlns:dc=\"http://purl.org/dc/elements/1.1/\">artikel</dc:subject><dc:identifier xmlns:dc=\"http://purl.org/dc/elements/1.1/\">ddd:011140123:mpeg21:p001:a0001</dc:identifier><dc:source xmlns:dc=\"http://purl.org/dc/elements/1.1/\"><dc:source><pm:link pm:source=\"832675288\" pm:description=\"De Telegraaf\"/></dc:source></dc:source></pm:meta><pm:content pm:source=\"http://kranten.kb.nl/view/article/id/ddd:011140123:mpeg21:p001:a0001\" pm:id=\"ddd:011140123:mpeg21:p001:a0001\"><title pm:id=\"ddd:011140123:mpeg21:p001:a0001.t\">Ook Noord-Korea en China willen praten over wapenstilstand RIDGWAY\\'S OPROEP AANVAARD Ontmoeting bij Kaesong (aan 38ste) voorgesteld MAAR EERST OVER 10 \\xc3\\x80 14 DAGEN</title><text><p pm:id=\"ddd:011140123:mpeg21:p001:a0001.1\">TOKIO, 2 Juli. \\xe2\\x80\\x94 De opperbevelhebbers van'\n"
     ]
    }
   ],
   "source": [
    "print(content[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.004587450001054094\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "import xmltodict, json\n",
    "\n",
    "\n",
    "start = timeit.timeit()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "o = xmltodict.parse(content)\n",
    "\n",
    "# use xmltodict to convert xml file to json (elasticsearch needs json input)\n",
    "#make json dump\n",
    "dump = json.dumps(o) # '{\"e\": {\"a\": [\"text\", \"text\"]}}'\n",
    "\n",
    "\n",
    "end = timeit.timeit()\n",
    "\n",
    "print (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GET DATE FROM ARTICLE\n",
    "def get_date(i):\n",
    "    return o['pm:KBroot']['pm:root'][i]['pm:meta']['dc:date']['#text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GET TITEL FROM ARTICLE\n",
    "def get_title(i):\n",
    "    try:\n",
    "        return o['pm:KBroot']['pm:root'][i]['pm:content']['title']['#text']\n",
    "    except (KeyError):\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GET TEXT FROM ARTICLE\n",
    "def get_text(i):\n",
    "    #sometimes, articles have more than 1 #text field\n",
    "    try:\n",
    "        return o['pm:KBroot']['pm:root'][i]['pm:content']['text']['p']['#text']\n",
    "    except (TypeError):\n",
    "        try:\n",
    "            text = ''\n",
    "            for j in range(len(o['pm:KBroot']['pm:root'][i]['pm:content']['text']['p'])):\n",
    "                text = text + o['pm:KBroot']['pm:root'][i]['pm:content']['text']['p'][j]['#text']\n",
    "            return text\n",
    "        # in very rare cases where other errors occur, return empty string\n",
    "        except (TypeError):\n",
    "            return ''\n",
    "    except (KeyError):\n",
    "        return ''\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "telegraaf = list()\n",
    "\n",
    "for i in range(len(o['pm:KBroot']['pm:root'])):\n",
    "    telegraaf.append({'_type':'article', '_index':'telegraaf', 'id':i, 'date':get_date(i), 'title':get_title(i), 'text':get_text(i)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_index': 'telegraaf',\n",
       " '_type': 'article',\n",
       " 'date': '1951-07-02',\n",
       " 'id': 12,\n",
       " 'text': 'DOETINCHEM, 1 JuH. — In ds afgelopen nacht ontstond in Doetir.chem tussen een aantal families van de buurt Het Fort een ruzie, die later werd gevolgd door een hevige vechtpartij, waarbij verscheidene personen gebruik maakten van steekwapens. De dertigjarige gehuwde H. E„ handelaar in metalen en lompen en vader vati vüf kinderen, kreeg een steek in de borststreek. Hij zakte in elkaar au overleed voor zijn woning. De ruzie ging in hoofdzaak tussen de families E. en Van D. Geide waren met een aantal andere personen Zaterdagavond naar de kermis in Doesburg geweest. Daarbij was veel aan Bacchus geofferd. Na de noodlottige vechtpartij zon een toegesnelde menigte mensen op wraak. Men begaf zich naar de woning van Van D., die aansprakelijk werd gesteld voor het ongeluk. De ruiten van zUn woning werden ingegooid. Enige toegesnelde agenten van politie konden nog juist verhinderen, dat men de woning var Van D. binnendrong. Een aantal arrestanten is op het politiebureau ingesloten. Het onderzoek word* belemmerd doordat verklaringen zijn afgelegd, die tegenstrijdig zijn.',\n",
       " 'title': 'Man doodgestoken in Doetinchem Noodlottige familietwist na kermisbezoek'}"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telegraaf[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37375, [])"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import  helpers\n",
    "\n",
    "# add bulk to elasticsearch\n",
    "helpers.bulk(es,telegraaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_shards': {'failed': 0, 'successful': 50, 'total': 50},\n",
       " 'hits': {'hits': [{'_id': 'AVgE2rtLpwdMr7iZJtjA',\n",
       "    '_index': 'telegraaf',\n",
       "    '_score': 1.2440497,\n",
       "    '_source': {'date': '1951-09-05',\n",
       "     'id': 12144,\n",
       "     'text': 'DEN HAAG, 4 Sept, — Het oorspronkelijke detachement Verenigde Naties is op 29 Augustus uit Japan naar Nederland vertrokken.',\n",
       "     'title': 'Korea-vrijwilligers'},\n",
       "    '_type': 'article'},\n",
       "   {'_id': 'AVgE2rhopwdMr7iZJtgj',\n",
       "    '_index': 'telegraaf',\n",
       "    '_score': 1.234184,\n",
       "    '_source': {'date': '1951-09-05',\n",
       "     'id': 11987,\n",
       "     'text': 'DEN HAAG, 4 Sept. — Het oorspronkelijke detachement Verenigde Naties is op 29 Augustus uit Japan naar Nederland vertrokken.',\n",
       "     'title': 'Korea-vrijwilligers'},\n",
       "    '_type': 'article'},\n",
       "   {'_id': 'AVgE2r6zpwdMr7iZJtpG',\n",
       "    '_index': 'telegraaf',\n",
       "    '_score': 1.1415126,\n",
       "    '_source': {'date': '1951-09-07',\n",
       "     'id': 12534,\n",
       "     'text': 'SAN FRANCISCO, 6 Sept. — Amerika verwacht Maandag a.s. een defensiepact met Japan te sluiten, verklaarde hier vandaag de republikeinse senator Bridges. De onderhandelingen hierover zijn nog gaande, maar over de voornaamste punten was reeds overeenstemming bereikt. Deze punten van accoord zouden de volgende zün: 1. Amerika behoudt land-, zeeen luohtbases in Japan. 2. Amerika kan deze bases benutten bij het weerstaan van agressie „in elke richting\". 3. Het getal der Amerikaanse strijdkraohten in Japan zal niet aan beperkingen gebonden zijn. (Reuter).',\n",
       "     'title': 'Maandag verwacht: Veiligheidspact V.S.-Japan'},\n",
       "    '_type': 'article'},\n",
       "   {'_id': 'AVgE2wTXpwdMr7iZJyE0',\n",
       "    '_index': 'telegraaf',\n",
       "    '_score': 1.1415126,\n",
       "    '_source': {'date': '1951-11-30',\n",
       "     'id': 30692,\n",
       "     'text': 'DJAKARTA, 29 Nov. — In een officiële mededeling van de regering van Indonesië wordt gezegd. dat het mislukken van de handelsbesprekingen met Japan zijn invloed zal doen gelden op het handelsverkeer. Op korte termijn zal de invoer van bepaalde goederen uit Japan worden beperkt en van andere Japanse goederen verboden. Een ambtelijke commissie zal de omschakeling van de Indonesische handel met Japan op de handel met andere landen voorbereiden.',\n",
       "     'title': 'INDONESIË ZAL INVOER UIT JAPAN BEPERKEN'},\n",
       "    '_type': 'article'},\n",
       "   {'_id': 'AVgE2rtMpwdMr7iZJtmu',\n",
       "    '_index': 'telegraaf',\n",
       "    '_score': 1.0945872,\n",
       "    '_source': {'date': '1951-09-07',\n",
       "     'id': 12382,\n",
       "     'text': 'SAN FRANCISCO, 6 Sept. — Amerika verwacht Maandag a.s. een defensiepact met Japan te sluiten, verklaarde hier vandaag de republikeinse senator Bridges. De onderhandelingen hierover zijn nog gaande, maar over de voornaamste punten was reeds overeenstemming bereikt. Deze punten van accoord zouden de volgende zijn: 1. Amerika behoudt land-, zeeen lucihtbases in Japan. 2. Amerika kan deze bases benutten bij het weerstaan van agressie „in elke richting\". 3. Het getal der Amerikaanse strijdkrachten in Japan zal niet aan beperkingen gebonden zijn. (Reuter).',\n",
       "     'title': 'Maandag verwacht: Veiligheidspact V.S.-Japan'},\n",
       "    '_type': 'article'},\n",
       "   {'_id': 'AVgE2t9ppwdMr7iZJvOx',\n",
       "    '_index': 'telegraaf',\n",
       "    '_score': 1.0663283,\n",
       "    '_source': {'date': '1951-09-01',\n",
       "     'id': 19041,\n",
       "     'text': 'Engeland en Japan hebben een sterllng-betalingsovereenkomst getekend, welke de weg baant voor een grotere handel tussen beide landen. Het verdrag, dat onmiddellijk van kracht wordt en geldigheidsduur heeft van 12 maanden, heeft ten doel de beperkingen op de betalingen tussen Japan en het sterling-gebied te verzachten en hierdoor meer normale financiële betrekkingen tussen deze landen te scheppen.Het voorziet in de vereffening in sterling van betalingen tussen Inwoners van Japan en van het rterlinggebled. Gedurende de periode van de overeenkomst zal Japan de gelegenheid hebben de multilaterale handel te ontwikkelen.',\n",
       "     'title': 'Betalingsaccoord Engeland-Japan'},\n",
       "    '_type': 'article'},\n",
       "   {'_id': 'AVgE2r60pwdMr7iZJtuN',\n",
       "    '_index': 'telegraaf',\n",
       "    '_score': 0.99737126,\n",
       "    '_source': {'date': '1951-09-10',\n",
       "     'id': 12861,\n",
       "     'text': 'SAN FRANCISCO, 9 Sept. — Weiuige uren na de plechtige ondertekening van het Ja.panse vredesverdrag — een plechtigheid waaraan de Sovjet-Unie, Polen en Tsjechoslovakijc niet deelnamen —• hebben Amerika en Japan een veilighcidsvcrdrag getekend, dat de Verenigde Staten het recht geeft „land- lucht- en marincbases in en om Japan te handhaven, nadat de geallieerde bezetting door het Japanse verdrag is geëindigd\".',\n",
       "     'title': 'Na ondertekening vredesverdrag te San Francisco AMERIKA SLUIT EEN PACT MET JAPAN Recht op bases vastgelegd Nu bezetting formeel ten einde is'},\n",
       "    '_type': 'article'},\n",
       "   {'_id': 'AVgE2rtLpwdMr7iZJthA',\n",
       "    '_index': 'telegraaf',\n",
       "    '_score': 0.94150376,\n",
       "    '_source': {'date': '1951-09-05',\n",
       "     'id': 12016,\n",
       "     'text': 'Maar er kan geen vooruitgang gemaakt worden, wanneer het Jafianse volk en zijn buren in de Stue Oceaan niet beschermd worden tegen de dreiging van agressie. Een van de voornaamste zorgen van de V.S. was derhalve geweest; Japan voor agressie te beveiligen, waarbij echter \"~>orkomen moest worden, dat Japan zeli de veiligheid van andere landen zou gaan bedreigen. „Om dit te bereiken moet Japan onder het UNO-handvest en onder de bescherming van de wederzijdse verplichtingen der leden van de UNO worden gebracht. Japan dient daarom zo spoedig mogelijk strijdkrachten in het leven te roepen, die zouden moeten samenwerken met die der andere landen. De Amerikaanse president vermeldde in dit verband o.a. de veiligheidspacten, die de V.S. met Australië, Nieuw-Zeeland en de Philippljnen hebben gesloten. De Japanse bijdrage zou echter geen offensieve bedreiging vormen.',\n",
       "     'title': 'Japans defensie'},\n",
       "    '_type': 'article'},\n",
       "   {'_id': 'AVgE2v6SpwdMr7iZJx2Z',\n",
       "    '_index': 'telegraaf',\n",
       "    '_score': 0.94150376,\n",
       "    '_source': {'date': '1951-11-27',\n",
       "     'id': 29769,\n",
       "     'text': '(Van onze Haagse redactie). DEN HAAG, 26 Nov. — Binnenkort is de indiening te verwachten van een wetsontwerp tot Goedkeuring van het vredesverdrag met Japan. Zijn wij wel ingelicht, dan bevindt dit wetsontwerp zich reeds bij de Raad van State.',\n",
       "     'title': 'Wetsontwerp onderweg Vrede met Japan'},\n",
       "    '_type': 'article'},\n",
       "   {'_id': 'AVgE2xBjpwdMr7iZJym8',\n",
       "    '_index': 'telegraaf',\n",
       "    '_score': 0.94150376,\n",
       "    '_source': {'date': '1951-12-11',\n",
       "     'id': 32876,\n",
       "     'text': 'HELSINKI, 10 Dec. — Bii het Finse organisatiecomité zijn tbans ook de inschrijvingen van Japan en Singapore binnengekomen. Het totaalaan. tal landen, dat aan de 01. zomerspelen deelneemt, ls nu tot 50 gestegen.',\n",
       "     'title': 'Vijftig teams voor Helsinki'},\n",
       "    '_type': 'article'}],\n",
       "  'max_score': 1.2440497,\n",
       "  'total': 308},\n",
       " 'timed_out': False,\n",
       " 'took': 41}"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#e.g. simple search for \"Japan\" in text\n",
    "\n",
    "HOST = 'http://localhost:9200/'\n",
    "es = Elasticsearch(hosts=[HOST])\n",
    "\n",
    "\n",
    "query={\n",
    "  \"query\": {\n",
    "    \"bool\": {\n",
    "        \"must\": [\n",
    "              { \"match\": {\"text\": \"Japan\"}}\n",
    "        ]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "es.search(body=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NEXT STEP: DUMP TELEGRAAF LIST TO ELASTICSEARCH (SEE TUTORIAL NOTEBOOK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make 1 big json object4\n",
    "# store this in elasticsearch\n",
    "# find document types (for facets)\n",
    "\n",
    "# store these things in elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create index telegraaf\n",
    "es.indices.create('telegraaf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# delete index telegraaf\n",
    "#es.indices.delete(index='telegraaf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_shards': {'failed': 0, 'successful': 5, 'total': 5}, 'count': 37375}"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.count(index='telegraaf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment \n",
    "\n",
    "\n",
    "### Standard option\n",
    "<p>Create a search engine for the <a href=\"http://data.politicalmashup.nl/arjan/telegraaf/\">telegraaf newspaper collection</a> using  ElasticSearch. Make facets for years and document types.\n",
    "            Pay attention to telephone numbers (in mini advertisements). Hieronder een voorbeeld van 1 document (= 1 artikeltje).\n",
    "            <br/> Je ziet dat er zelfs een link naar de bron tekst (als plaatje) instaat. De URL linked door naar de nieuwe url <a href=\"http://www.delpher.nl/nl/kranten/view?identifier=ddd%3A010563762%3Ampeg21%3Aa0005&coll=ddd\">http://www.delpher.nl/nl/kranten/view?identifier=ddd%3A010563762%3Ampeg21%3Aa0005&amp;coll=ddd</a>\n",
    "            ElasticSearch gebruikt een JSON formaat als invoer, en dit is dus makkelijk om te zetten naar JSON.</p>\n",
    "<pre>\n",
    "&lt;pm:root>\n",
    "&lt;pm:docinfo/>\n",
    "&lt;pm:meta>\n",
    "&lt;dc:date xmlns:dc=\"http://purl.org/dc/elements/1.1/\">1923-03-01&lt;/dc:date>\n",
    "&lt;dc:subject xmlns:dc=\"http://purl.org/dc/elements/1.1/\">artikel&lt;/dc:subject>\n",
    "&lt;dc:identifier xmlns:dc=\"http://purl.org/dc/elements/1.1/\"\n",
    ">ddd:010563762:mpeg21:p001:a0005&lt;/dc:identifier>\n",
    "&lt;dc:source xmlns:dc=\"http://purl.org/dc/elements/1.1/\">\n",
    "&lt;dc:source>\n",
    "&lt;pm:link pm:source=\"832675288\" pm:description=\"De Telegraaf\"/>\n",
    "&lt;/dc:source>\n",
    "&lt;/dc:source>\n",
    "&lt;/pm:meta>\n",
    "&lt;pm:content pm:source=\"http://kranten.kb.nl/view/article/id/ddd:010563762:mpeg21:p001:a0005\"\n",
    "pm:id=\"ddd:010563762:mpeg21:p001:a0005\">\n",
    "&lt;title pm:id=\"ddd:010563762:mpeg21:p001:a0005.t\">De jongste maaregelen op den Rechter-\n",
    "Rijn-oeven.&lt;/title>\n",
    "&lt;text>\n",
    "&lt;p pm:id=\"ddd:010563762:mpeg21:p001:a0005.1\">â–  volgende redenen rijn bezet: lo. ter vereenvcudi-f\n",
    "ging ran het douane-wezen en 2o. wegens fit' demonstratieÂ» en vergaderingen, welke in deÂ»e gebieden\n",
    "zijn gehouden en gericht waren tegen de bezettingstroepen en de bezettingsautoriteiten. De\n",
    "rijkscommissaris voor de bezette genie den heeft geweigerd, deze kennisgevins door te zenden. â€”\n",
    "(Wolft},&lt;/p>\n",
    "&lt;/text>\n",
    "&lt;/pm:content>\n",
    "&lt;/pm:root>\n",
    "</pre>\n",
    "   \n",
    "### Other options\n",
    "* Provided that you come up with a non trivial collection you can create a search engine using a different collection and also different software, as long as it is not done in MySQL.\n",
    "* Discuss this with the assistants.\n",
    "    * Convince us that your data set is interesting and your software solution worthwhile investigating.\n",
    "* For the presentations it is fun to see something else.\n",
    "* Usually it has a positive effect on your mark if you do something completely different ;-)\n",
    "* You should do the same requirements.\n",
    "\n",
    "#### Examples of other collections\n",
    "* [Hillary Clinton Email collection](https://archive.org/details/hillary-clinton-emails-august-31-release) See also our <http://maartenmarx.nl/teaching/zoekmachines/Data/> folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h2>Requirements</h2>\n",
    "        <p>Each of the following points <strong>must</strong> be addressed. Create a seperate page on the wiki for each point. Make sure these pages can be found from the menu of your wiki. \n",
    "        Explain what you did, and exemplify with links to screenshots/a working system.</p>\n",
    "        <ol>\n",
    "        <li>Search as we know it from Google. Give a result page (SERP), with links to the documents and some description of each hit.</li>\n",
    "            <li>Advanced search. Let a user be able to search in several fields, also in several fields simulteanously. Queries like \"return articles with a title  about XXX  and which are   about YYY in the period ZZZ\" should be possible.\n",
    "             </li>\n",
    "        <li>Do one of the following:\n",
    "            <ol><li>Represent the hits of a query with a wordcloud of 25-50 informative words. The wordcloud should somehow summarise what the collection has to say about the query.\n",
    "            You may think of these words as words that you could add to the query in order to improve recall (blind relevance feedback/query expansion). </li>\n",
    "                <li>Represent each document   with a word-cloud. Also make word-clouds for the question and for the answer.\n",
    "            EXAMPLE: The html files in <a href=\"http://data.politicalmashup.nl/arjan/odeii/data_as_html/\">http://data.politicalmashup.nl/arjan/odeii/data_as_html/</a> contain such wordcloud summaries, which work rather well.</li></ol>\n",
    "        <br/>You can use several techniques to get rid of high frequency, but meaningless words: of course IDF, but also mutual information (see 13.5.1), or of course the technique from the paper by Kaptein et al on wordclouds.\n",
    "        </li>\n",
    "          <!--  <li>Group (nearly) identical documents. It is bad if two or more of the precious places of your top ten hits are occupied by near identical copies of a document.\n",
    "            Even more so if it is not relevant! So, get rid of these, by grouping them for instance. You get an idea of these duplicates if you search for \"neuken\".</li>\n",
    "            -->\n",
    "            <li>Give next to a traditional list of results, a timeline in which you indicate how many hits there are over time.</li>\n",
    "            <li>Provide Faceted Search next to the traditional list of results. For the \"Telegraaf\" collectie, use the <tt>dc:subject</tt> element as facet values.</li>\n",
    "            <li><strong>Evaluate your results</strong> Let 2 persons assess the relevancy of the top 10 documents for <strong>5 different queries</strong>. Compute Cohen's kappa. Determine the average precision at 10 for your system based on these 10 queries, and the two relevance assesments. \n",
    "                Also plot the P@10 (for both judges) for each query, showing differences in hard and easy queries.  \n",
    "                Describe clearly how you solved differences in judgements.\n",
    "            <br/>\n",
    "            Create your queries in the following format:\n",
    "<pre>\n",
    "&lt;topic number=\"6\"  >\n",
    "    &lt;query>kcs&lt;/query>\n",
    "    &lt;description>Find information on the Kansas City Southern railroad.\n",
    "    &lt;/description>\n",
    "\n",
    "&lt;/topic>\n",
    "\n",
    "&lt;topic number=\"16\"  >\n",
    "    &lt;query>arizona game and fish&lt;/query>\n",
    "    &lt;description>I'm looking for information about fishing and hunting\n",
    "    in Arizona.\n",
    "    &lt;/description>\n",
    "&lt;/topic>\n",
    "</pre>\n",
    "    So, both provide the actual query, and a description of the information need that was behind the query.\n",
    "    <br/>\n",
    "    Give a small set of clear guidelines for judging the results, and let your judges follow these guidelines.\n",
    "    <br/>\n",
    "    It is far more interesting to have difficult queries (both for the search engine and for the judges) than to have queries on which all ten retrieved documents are relevant.\n",
    "    So, try to create a good list of information needs.\n",
    "\n",
    "</li>\n",
    "<li>Change the ranking of your system, compute the average precision at 10 using your 10 queries, compare the results to your old system, and EXPLAIN what is going on.</li>\n",
    "</ol>\n",
    "\n",
    "<h2>Presentation</h2>\n",
    "<p>During your presentation you should have a live working search engine, that you demonstrate on the spot. Your presentation should be structured so that you will show all  requirements.\n",
    "You will be asked to show how your system works using information needs coming  from the audience.</p>\n",
    "<p>**Hint:** focus on a special aspect of your project. Everyone has done something similar, so your audience knows what was hard and what was terrible. Pick something you think will interest them.</p>\n",
    "\n",
    "\n",
    "<h2>How you will be marked</h2>\n",
    "<ul>\n",
    "    <li>Sent the URL of your guthub wiki to Maarten Marx BEFORE the presentation.</li>\n",
    "    <li>The first page of the wiki should contain:\n",
    "        <ol>\n",
    "            <li>The names and student numbers of the project members</li>\n",
    "            <li>A link to the slides of your presentation</li>\n",
    "            <li>A table of contents, with links to pages on the wiki adressing one of each of the \"must-have\" points listed above.\n",
    "            <br/>During grading, you will receive points for each of the points. So make it crystal clear where they are adressed in your wiki. Use one page per point.</li>\n",
    "\n",
    "\n",
    "</ol>\n",
    "</li>\n",
    "<li>The page for each point should contain, all rather briefly,\n",
    "<ol>\n",
    "<li>What you did and why you choose to do it in your special way.</li>\n",
    "<li>Examples of what works, and what does not work (very well).</li>\n",
    "<li>An evaluation of the quality of your work in 3-4 sentences.</li>\n",
    "</ol></li>\n",
    "<li>Clickable links to a live working demo are <strong>highly appreciated</strong>. </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
